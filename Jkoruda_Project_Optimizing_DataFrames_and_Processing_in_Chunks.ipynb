{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y7eHGTSKv8TW",
        "ZJ7UJlKnwJk3",
        "StemrBe2wkMj",
        "8BtAVP8fw3OH",
        "22oYzgXnxIcV",
        "DMJVaj_kxj42"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7eHGTSKv8TW"
      },
      "source": [
        "# Project Notebook: Optimizing DataFrames and Processing in Chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ7UJlKnwJk3"
      },
      "source": [
        "## 1. Introduction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUyK3GcBv9mC"
      },
      "source": [
        "In this project, we'll practice working with chunked dataframes and optimizing a dataframe's memory usage. We'll be working with financial lending data from Lending Club, a marketplace for personal loans that matches borrowers with investors. You can read more about the marketplace on its website.\n",
        "\n",
        "The Lending Club's website lists approved loans. Qualified investors can view the borrower's credit score, the purpose of the loan, and other details in the loan applications. Once a lender is ready to back a loan, it selects the amount of money it wants to fund. When the loan amount the borrower requested is fully funded, the borrower receives the money, minus the origination fee that Lending Club charges.\n",
        "\n",
        "We'll be working with a dataset of loans approved from 2007-2011 (https://bit.ly/3H2XVgC). We've already removed the desc column for you to make our system run more quickly.\n",
        "\n",
        "If we read in the entire data set, it will consume about 67 megabytes of memory. Let's imagine that we only have 10 megabytes of memory available throughout this project, so you can practice the concepts you learned in the last two lessons.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "1. Read in the first five lines from `loans_2007.csv` (https://bit.ly/3H2XVgC) and look for any data quality issues.\n",
        "\n",
        "2. Read in the first 1000 rows from the data set, and calculate the total memory usage for these rows. Increase or decrease the number of rows to converge on a memory usage under five megabytes (to stay on the conservative side)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc9NLSZ5vXPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e015d351-036d-4d11-91fc-8810f8dffda6"
      },
      "source": [
        "# Importing pandas\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = 99\n",
        "\n",
        "# Download the loans_2007.csv\n",
        "!wget -O loans_2007.csv https://bit.ly/3H2XVgC\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-27 14:04:32--  https://bit.ly/3H2XVgC\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://archive.org/download/loans_2007/loans_2007.csv [following]\n",
            "--2023-01-27 14:04:32--  https://archive.org/download/loans_2007/loans_2007.csv\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia902300.us.archive.org/3/items/loans_2007/loans_2007.csv [following]\n",
            "--2023-01-27 14:04:33--  https://ia902300.us.archive.org/3/items/loans_2007/loans_2007.csv\n",
            "Resolving ia902300.us.archive.org (ia902300.us.archive.org)... 207.241.228.50\n",
            "Connecting to ia902300.us.archive.org (ia902300.us.archive.org)|207.241.228.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15638149 (15M) [text/csv]\n",
            "Saving to: ‘loans_2007.csv’\n",
            "\n",
            "loans_2007.csv      100%[===================>]  14.91M  9.39MB/s    in 1.6s    \n",
            "\n",
            "2023-01-27 14:04:35 (9.39 MB/s) - ‘loans_2007.csv’ saved [15638149/15638149]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read first five lines and look for data quality issues\n",
        "df_loans = pd.read_csv('loans_2007.csv', nrows=5)\n",
        "print(df_loans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ao73AyZ1Ju0",
        "outputId": "4b839998-31a2-4436-e178-67f1fbc918f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
            "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
            "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
            "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
            "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
            "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
            "\n",
            "  int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
            "0   10.65%       162.87     B        B2                       NaN  10+ years   \n",
            "1   15.27%        59.83     C        C4                     Ryder   < 1 year   \n",
            "2   15.96%        84.33     C        C5                       NaN  10+ years   \n",
            "3   13.49%       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
            "4   12.69%        67.79     B        B5  University Medical Group     1 year   \n",
            "\n",
            "  home_ownership  annual_inc verification_status   issue_d  loan_status  \\\n",
            "0           RENT     24000.0            Verified  Dec-2011   Fully Paid   \n",
            "1           RENT     30000.0     Source Verified  Dec-2011  Charged Off   \n",
            "2           RENT     12252.0        Not Verified  Dec-2011   Fully Paid   \n",
            "3           RENT     49200.0     Source Verified  Dec-2011   Fully Paid   \n",
            "4           RENT     80000.0     Source Verified  Dec-2011      Current   \n",
            "\n",
            "  pymnt_plan         purpose                 title zip_code addr_state    dti  \\\n",
            "0          n     credit_card              Computer    860xx         AZ  27.65   \n",
            "1          n             car                  bike    309xx         GA   1.00   \n",
            "2          n  small_business  real estate business    606xx         IL   8.72   \n",
            "3          n           other              personel    917xx         CA  20.00   \n",
            "4          n           other              Personal    972xx         OR  17.94   \n",
            "\n",
            "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
            "0          0.0         Jan-1985             1.0       3.0      0.0    13648.0   \n",
            "1          0.0         Apr-1999             5.0       3.0      0.0     1687.0   \n",
            "2          0.0         Nov-2001             2.0       2.0      0.0     2956.0   \n",
            "3          0.0         Feb-1996             1.0      10.0      0.0     5598.0   \n",
            "4          0.0         Jan-1996             0.0      15.0      0.0    27783.0   \n",
            "\n",
            "  revol_util  total_acc initial_list_status  out_prncp  out_prncp_inv  \\\n",
            "0      83.7%        9.0                   f       0.00           0.00   \n",
            "1       9.4%        4.0                   f       0.00           0.00   \n",
            "2      98.5%       10.0                   f       0.00           0.00   \n",
            "3        21%       37.0                   f       0.00           0.00   \n",
            "4      53.9%       38.0                   f     461.73         461.73   \n",
            "\n",
            "    total_pymnt  total_pymnt_inv  total_rec_prncp  total_rec_int  \\\n",
            "0   5863.155187          5833.84          5000.00         863.16   \n",
            "1   1008.710000          1008.71           456.46         435.17   \n",
            "2   3005.666844          3005.67          2400.00         605.67   \n",
            "3  12231.890000         12231.89         10000.00        2214.92   \n",
            "4   3581.120000          3581.12          2538.27        1042.85   \n",
            "\n",
            "   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d  \\\n",
            "0                0.00        0.00                     0.00     Jan-2015   \n",
            "1                0.00      117.08                     1.11     Apr-2013   \n",
            "2                0.00        0.00                     0.00     Jun-2014   \n",
            "3               16.97        0.00                     0.00     Jan-2015   \n",
            "4                0.00        0.00                     0.00     Jun-2016   \n",
            "\n",
            "   last_pymnt_amnt last_credit_pull_d  collections_12_mths_ex_med  \\\n",
            "0           171.62           Jun-2016                         0.0   \n",
            "1           119.66           Sep-2013                         0.0   \n",
            "2           649.91           Jun-2016                         0.0   \n",
            "3           357.48           Apr-2016                         0.0   \n",
            "4            67.79           Jun-2016                         0.0   \n",
            "\n",
            "   policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
            "0          1.0       INDIVIDUAL             0.0                       0.0   \n",
            "1          1.0       INDIVIDUAL             0.0                       0.0   \n",
            "2          1.0       INDIVIDUAL             0.0                       0.0   \n",
            "3          1.0       INDIVIDUAL             0.0                       0.0   \n",
            "4          1.0       INDIVIDUAL             0.0                       0.0   \n",
            "\n",
            "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
            "0          0.0                   0.0        0.0  \n",
            "1          0.0                   0.0        0.0  \n",
            "2          0.0                   0.0        0.0  \n",
            "3          0.0                   0.0        0.0  \n",
            "4          0.0                   0.0        0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By trying out different values, we see that 10,000 rows takes up 4MB, which is\n",
        "# less than 5MB as desired\n",
        "df_loans = pd.read_csv('loans_2007.csv', nrows=10000)\n",
        "print(df_loans.info(memory_usage=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrfXAPCG1o6H",
        "outputId": "1bb7c781-2b5f-4acf-cbb7-61428119afdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   id                          10000 non-null  int64  \n",
            " 1   member_id                   10000 non-null  float64\n",
            " 2   loan_amnt                   10000 non-null  float64\n",
            " 3   funded_amnt                 10000 non-null  float64\n",
            " 4   funded_amnt_inv             10000 non-null  float64\n",
            " 5   term                        10000 non-null  object \n",
            " 6   int_rate                    10000 non-null  object \n",
            " 7   installment                 10000 non-null  float64\n",
            " 8   grade                       10000 non-null  object \n",
            " 9   sub_grade                   10000 non-null  object \n",
            " 10  emp_title                   9348 non-null   object \n",
            " 11  emp_length                  9645 non-null   object \n",
            " 12  home_ownership              10000 non-null  object \n",
            " 13  annual_inc                  10000 non-null  float64\n",
            " 14  verification_status         10000 non-null  object \n",
            " 15  issue_d                     10000 non-null  object \n",
            " 16  loan_status                 10000 non-null  object \n",
            " 17  pymnt_plan                  10000 non-null  object \n",
            " 18  purpose                     10000 non-null  object \n",
            " 19  title                       10000 non-null  object \n",
            " 20  zip_code                    10000 non-null  object \n",
            " 21  addr_state                  10000 non-null  object \n",
            " 22  dti                         10000 non-null  float64\n",
            " 23  delinq_2yrs                 10000 non-null  float64\n",
            " 24  earliest_cr_line            10000 non-null  object \n",
            " 25  inq_last_6mths              10000 non-null  float64\n",
            " 26  open_acc                    10000 non-null  float64\n",
            " 27  pub_rec                     10000 non-null  float64\n",
            " 28  revol_bal                   10000 non-null  float64\n",
            " 29  revol_util                  9997 non-null   object \n",
            " 30  total_acc                   10000 non-null  float64\n",
            " 31  initial_list_status         10000 non-null  object \n",
            " 32  out_prncp                   10000 non-null  float64\n",
            " 33  out_prncp_inv               10000 non-null  float64\n",
            " 34  total_pymnt                 10000 non-null  float64\n",
            " 35  total_pymnt_inv             10000 non-null  float64\n",
            " 36  total_rec_prncp             10000 non-null  float64\n",
            " 37  total_rec_int               10000 non-null  float64\n",
            " 38  total_rec_late_fee          10000 non-null  float64\n",
            " 39  recoveries                  10000 non-null  float64\n",
            " 40  collection_recovery_fee     10000 non-null  float64\n",
            " 41  last_pymnt_d                9985 non-null   object \n",
            " 42  last_pymnt_amnt             10000 non-null  float64\n",
            " 43  last_credit_pull_d          10000 non-null  object \n",
            " 44  collections_12_mths_ex_med  10000 non-null  float64\n",
            " 45  policy_code                 10000 non-null  float64\n",
            " 46  application_type            10000 non-null  object \n",
            " 47  acc_now_delinq              10000 non-null  float64\n",
            " 48  chargeoff_within_12_mths    10000 non-null  float64\n",
            " 49  delinq_amnt                 10000 non-null  float64\n",
            " 50  pub_rec_bankruptcies        10000 non-null  float64\n",
            " 51  tax_liens                   10000 non-null  float64\n",
            "dtypes: float64(30), int64(1), object(21)\n",
            "memory usage: 4.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StemrBe2wkMj"
      },
      "source": [
        "## 2. Exploring the Data in Chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4p982Dwor5"
      },
      "source": [
        "Let's familiarize ourselves with the columns to see which ones we can optimize. In the first lesson, we explored column types by reading in the full dataframe. In this project, let's try to understand the column types better while using dataframe chunks.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "For each chunk:\n",
        "* How many columns have a numeric type? \n",
        "* How many have a string type?\n",
        "* How many unique values are there in each string column? How many of the string columns contain values that are less than 50% unique?\n",
        "* Which float columns have no missing values and could be candidates for conversion to the integer type?\n",
        "* Calculate the total memory usage across all of the chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjTUXAnJwzdx"
      },
      "source": [
        "# import function to tell whether dtype is numeric\n",
        "from pandas.api.types import is_numeric_dtype\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No. of Columns with numeric and non-numeric dtype\n",
        "\n",
        "df_loans_iter = pd.read_csv('loans_2007.csv', chunksize=10000)\n",
        "# Use next() to get the first chunk, since df_loans is an iterable\n",
        "df_loans = next(df_loans_iter)\n",
        "\n",
        "num_numeric = 0\n",
        "num_non_numeric = 0\n",
        "for col in df_loans:\n",
        "    if is_numeric_dtype(df_loans[col]):\n",
        "        num_numeric += 1\n",
        "    else:\n",
        "        num_non_numeric += 1\n",
        "print('Number of numeric columns: ', num_numeric)\n",
        "print('Number of non-numeric columns i.e. strings: ', num_non_numeric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBHF_SQb2Mvq",
        "outputId": "b2be2391-fa1c-45cf-b38e-993925319049"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of numeric columns:  31\n",
            "Number of non-numeric columns i.e. strings:  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of unique columns in each string column\n",
        "# NB: df_loans is currently the first chunk\n",
        "\n",
        "df_loans_string = df_loans.select_dtypes(include=['object'])\n",
        "for col in df_loans_string:\n",
        "    num_unique = len(df_loans_string[col].value_counts())\n",
        "    print(col, num_unique, ', Ratio: ', num_unique / 10000) # 10000 is the chunksize\n",
        "\n",
        "# By inspecting the output below, ALL the string columns except emp_title have \n",
        "# less than 50% unique values."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWDxOSEb2cUL",
        "outputId": "391c794d-8cc0-42e9-d3a6-8de7e7996b43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "term 2 , Ratio:  0.0002\n",
            "int_rate 70 , Ratio:  0.007\n",
            "grade 7 , Ratio:  0.0007\n",
            "sub_grade 35 , Ratio:  0.0035\n",
            "emp_title 8171 , Ratio:  0.8171\n",
            "emp_length 11 , Ratio:  0.0011\n",
            "home_ownership 3 , Ratio:  0.0003\n",
            "verification_status 3 , Ratio:  0.0003\n",
            "issue_d 5 , Ratio:  0.0005\n",
            "loan_status 6 , Ratio:  0.0006\n",
            "pymnt_plan 1 , Ratio:  0.0001\n",
            "purpose 13 , Ratio:  0.0013\n",
            "title 4084 , Ratio:  0.4084\n",
            "zip_code 720 , Ratio:  0.072\n",
            "addr_state 45 , Ratio:  0.0045\n",
            "earliest_cr_line 465 , Ratio:  0.0465\n",
            "revol_util 1026 , Ratio:  0.1026\n",
            "initial_list_status 1 , Ratio:  0.0001\n",
            "last_pymnt_d 58 , Ratio:  0.0058\n",
            "last_credit_pull_d 59 , Ratio:  0.0059\n",
            "application_type 1 , Ratio:  0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# float columns without missing values\n",
        "df_loans_numeric = df_loans.select_dtypes(include=['float16', 'float32', 'float64'])\n",
        "for col in df_loans_numeric:\n",
        "    num_missing_vals = df_loans_numeric[col].isnull().sum()\n",
        "    print(col,  '=> Missing values: ', num_missing_vals) # 10000 is the chunksize\n",
        "\n",
        "# From inspecting the output below, non of the float columns have missing values\n",
        "# They are therefore all candidates for conversion to integers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgohm7BL2l6J",
        "outputId": "821282ec-44ea-4919-e52a-f68879c6751a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "member_id => Missing values:  0\n",
            "loan_amnt => Missing values:  0\n",
            "funded_amnt => Missing values:  0\n",
            "funded_amnt_inv => Missing values:  0\n",
            "installment => Missing values:  0\n",
            "annual_inc => Missing values:  0\n",
            "dti => Missing values:  0\n",
            "delinq_2yrs => Missing values:  0\n",
            "inq_last_6mths => Missing values:  0\n",
            "open_acc => Missing values:  0\n",
            "pub_rec => Missing values:  0\n",
            "revol_bal => Missing values:  0\n",
            "total_acc => Missing values:  0\n",
            "out_prncp => Missing values:  0\n",
            "out_prncp_inv => Missing values:  0\n",
            "total_pymnt => Missing values:  0\n",
            "total_pymnt_inv => Missing values:  0\n",
            "total_rec_prncp => Missing values:  0\n",
            "total_rec_int => Missing values:  0\n",
            "total_rec_late_fee => Missing values:  0\n",
            "recoveries => Missing values:  0\n",
            "collection_recovery_fee => Missing values:  0\n",
            "last_pymnt_amnt => Missing values:  0\n",
            "collections_12_mths_ex_med => Missing values:  0\n",
            "policy_code => Missing values:  0\n",
            "acc_now_delinq => Missing values:  0\n",
            "chargeoff_within_12_mths => Missing values:  0\n",
            "delinq_amnt => Missing values:  0\n",
            "pub_rec_bankruptcies => Missing values:  0\n",
            "tax_liens => Missing values:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory usage across all the chunks\n",
        "\n",
        "# Reset the iterable\n",
        "df_loans_iter = pd.read_csv('loans_2007.csv', chunksize=10000)\n",
        "# Iterate over all the chunks\n",
        "memory_used = 0\n",
        "for df_loans in df_loans_iter:\n",
        "    memory_used += df_loans.memory_usage(deep=True).sum()\n",
        "\n",
        "print('Total memory across chunks: ', memory_used)\n",
        "\n",
        "# From the output below, memory across chunks is 68.9MB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQJNKp7n2w_-",
        "outputId": "17ad0847-1e83-4534-9f0c-4d97fc46ffde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total memory across chunks:  68905389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BtAVP8fw3OH"
      },
      "source": [
        "## 3. Optimizing String Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkWArHAhw_bw"
      },
      "source": [
        "We can achieve the greatest memory improvements by converting the string columns to a numeric type. Let's convert all of the columns where the values are less than 50% unique to the category type, and the columns that contain numeric values to the `float` type.\n",
        "\n",
        "While working with dataframe chunks:\n",
        "* Determine which string columns you can convert to a numeric type if you clean them. For example, the `int_rate` column is only a string because of the % sign at the end.\n",
        "* Determine which columns have a few unique values and convert them to the category type. For example, you may want to convert the grade and `sub_grade` columns.\n",
        "Based on your conclusions, perform the necessary type changes across all chunks. * Calculate the total memory footprint, and compare it with the previous one."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean the string columns**\n",
        "\n",
        "Such cleaning involves e.g. stripping the '%' sign at the end of a string if doing so will make it convertible to a float."
      ],
      "metadata": {
        "id": "4yzXI8RO01We"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH0tcQlpxG9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14f76b6-22c3-48f8-f4e7-a274eba10947"
      },
      "source": [
        "df_loans_string = df_loans.select_dtypes(include=['object'])\n",
        "\n",
        "def strip_strings(df, to_strip):\n",
        "    '''\n",
        "    parameters:\n",
        "    - df: dataframe\n",
        "    - to_strip: the set of characters to be stripped\n",
        "    '''\n",
        "    for col in df:\n",
        "        # Ensure the column is a string. This enables the fn to work even if some\n",
        "        # columns of the df are not strings.\n",
        "        if not is_numeric_dtype(df[col]):\n",
        "            df[col] = df[col].str.rstrip(to_strip)\n",
        "\n",
        "# Test the strip_strings() function\n",
        "strip_strings(df_loans_string, '%')\n",
        "print(df_loans_string)\n",
        "\n",
        "# In the output of this cell (below), notict that '%' has been stripped off every\n",
        "# element in the 'int_rate' column.\n",
        "\n",
        "# The above works with the assumption that '%' at the end of a string ONLY signifies percentage\n",
        "# Other scenarios could arise in which '%' means something else, in which case more validation would\n",
        "# need to be done.\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    id        term int_rate  \\\n",
            "40000                                           598513   36 months    14.84   \n",
            "40001                                           585666   36 months    14.72   \n",
            "40002                                           598114   36 months    15.21   \n",
            "40003                                           598033   60 months    16.32   \n",
            "40004                                           597824   36 months    16.45   \n",
            "...                                                ...         ...      ...   \n",
            "42533                                            72176   36 months     9.33   \n",
            "42534                                            71623   36 months     8.38   \n",
            "42535                                            70686   36 months     7.75   \n",
            "42536  Total amount funded in policy code 1: 471701350         NaN      NaN   \n",
            "42537          Total amount funded in policy code 2: 0         NaN      NaN   \n",
            "\n",
            "      grade sub_grade                    emp_title emp_length home_ownership  \\\n",
            "40000     D        D1              The Arbor Group  10+ years       MORTGAGE   \n",
            "40001     C        C5              Eastside Dental   < 1 year       MORTGAGE   \n",
            "40002     D        D2                 CVS Caremark    4 years           RENT   \n",
            "40003     D        D5  Associatye Insurance Agency  10+ years            OWN   \n",
            "40004     E        E1       Motion Industries, Inc  10+ years            OWN   \n",
            "...     ...       ...                          ...        ...            ...   \n",
            "42533     B        B3                          NaN   < 1 year           RENT   \n",
            "42534     A        A5                          NaN   < 1 year           NONE   \n",
            "42535     A        A3                    Homemaker  10+ years       MORTGAGE   \n",
            "42536   NaN       NaN                          NaN        NaN            NaN   \n",
            "42537   NaN       NaN                          NaN        NaN            NaN   \n",
            "\n",
            "      verification_status   issue_d  \\\n",
            "40000     Source Verified  Oct-2010   \n",
            "40001        Not Verified  Oct-2010   \n",
            "40002        Not Verified  Oct-2010   \n",
            "40003     Source Verified  Oct-2010   \n",
            "40004            Verified  Oct-2010   \n",
            "...                   ...       ...   \n",
            "42533        Not Verified  Jun-2007   \n",
            "42534        Not Verified  Jun-2007   \n",
            "42535        Not Verified  Jun-2007   \n",
            "42536                 NaN       NaN   \n",
            "42537                 NaN       NaN   \n",
            "\n",
            "                                             loan_status pymnt_plan  \\\n",
            "40000  Does not meet the credit policy. Status:Fully ...          n   \n",
            "40001  Does not meet the credit policy. Status:Fully ...          n   \n",
            "40002  Does not meet the credit policy. Status:Fully ...          n   \n",
            "40003  Does not meet the credit policy. Status:Charge...          n   \n",
            "40004  Does not meet the credit policy. Status:Fully ...          n   \n",
            "...                                                  ...        ...   \n",
            "42533  Does not meet the credit policy. Status:Fully ...          n   \n",
            "42534  Does not meet the credit policy. Status:Fully ...          n   \n",
            "42535  Does not meet the credit policy. Status:Fully ...          n   \n",
            "42536                                                NaN        NaN   \n",
            "42537                                                NaN        NaN   \n",
            "\n",
            "                  purpose                            title zip_code  \\\n",
            "40000  debt_consolidation                   kiwidebtconsol    622xx   \n",
            "40001  debt_consolidation                 Consolidate Debt    130xx   \n",
            "40002  debt_consolidation                          PerLoan    750xx   \n",
            "40003      major_purchase                   Major Purchase    775xx   \n",
            "40004  debt_consolidation  Same Job 27 Years_Good Borrower    364xx   \n",
            "...                   ...                              ...      ...   \n",
            "42533               other                  Car repair bill    100xx   \n",
            "42534               other                     Buying a car    100xx   \n",
            "42535               other                   Aroundthehouse    068xx   \n",
            "42536                 NaN                              NaN      NaN   \n",
            "42537                 NaN                              NaN      NaN   \n",
            "\n",
            "      addr_state earliest_cr_line revol_util initial_list_status last_pymnt_d  \\\n",
            "40000         IL         Nov-1994       67.3                   f     Jul-2013   \n",
            "40001         NY         Jul-2005       25.6                   f     Apr-2011   \n",
            "40002         TX         Feb-1993       56.4                   f     Mar-2013   \n",
            "40003         TX         Aug-1996       91.9                   f     May-2014   \n",
            "40004         AL         Jul-1990       75.3                   f     Nov-2013   \n",
            "...          ...              ...        ...                 ...          ...   \n",
            "42533         NY              NaN        NaN                   f     Jun-2010   \n",
            "42534         NY              NaN        NaN                   f     Jun-2010   \n",
            "42535         CT              NaN        NaN                   f     Jun-2010   \n",
            "42536        NaN              NaN        NaN                 NaN          NaN   \n",
            "42537        NaN              NaN        NaN                 NaN          NaN   \n",
            "\n",
            "      last_credit_pull_d application_type  \n",
            "40000           Jul-2013       INDIVIDUAL  \n",
            "40001           Jun-2013       INDIVIDUAL  \n",
            "40002           Apr-2016       INDIVIDUAL  \n",
            "40003           Jul-2014       INDIVIDUAL  \n",
            "40004           Nov-2013       INDIVIDUAL  \n",
            "...                  ...              ...  \n",
            "42533           May-2007       INDIVIDUAL  \n",
            "42534           Aug-2007       INDIVIDUAL  \n",
            "42535           Feb-2015       INDIVIDUAL  \n",
            "42536                NaN              NaN  \n",
            "42537                NaN              NaN  \n",
            "\n",
            "[2538 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-87a4a089bff1>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].str.rstrip(to_strip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unique values in each string column\n",
        "If these are less than 50% for any column, they can be converted to 'categorical'."
      ],
      "metadata": {
        "id": "nlqriv1K1csZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of unique values in each string column\n",
        "# NB: df_loans is currently the first chunk\n",
        "\n",
        "df_loans_string = df_loans.select_dtypes(include=['object'])\n",
        "\n",
        "def count_unique(df):\n",
        "    for col in df:\n",
        "        num_unique = len(df[col].value_counts())\n",
        "        print(col, num_unique, ', Ratio: ', num_unique / 3000) # 3000 is the chunksize\n",
        "\n",
        "count_unique(df_loans_string)\n",
        "# By inspecting the output below, ALL the string columns except emp_title have \n",
        "# less than 50% unique values."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cin0vRr_1gjT",
        "outputId": "b8807eaa-650c-4978-df97-f42edfe6969a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id 2538 , Ratio:  0.846\n",
            "term 2 , Ratio:  0.0006666666666666666\n",
            "int_rate 249 , Ratio:  0.083\n",
            "grade 7 , Ratio:  0.0023333333333333335\n",
            "sub_grade 35 , Ratio:  0.011666666666666667\n",
            "emp_title 2207 , Ratio:  0.7356666666666667\n",
            "emp_length 11 , Ratio:  0.0036666666666666666\n",
            "home_ownership 5 , Ratio:  0.0016666666666666668\n",
            "verification_status 3 , Ratio:  0.001\n",
            "issue_d 41 , Ratio:  0.013666666666666667\n",
            "loan_status 2 , Ratio:  0.0006666666666666666\n",
            "pymnt_plan 1 , Ratio:  0.0003333333333333333\n",
            "purpose 14 , Ratio:  0.004666666666666667\n",
            "title 2004 , Ratio:  0.668\n",
            "zip_code 575 , Ratio:  0.19166666666666668\n",
            "addr_state 49 , Ratio:  0.01633333333333333\n",
            "earliest_cr_line 358 , Ratio:  0.11933333333333333\n",
            "revol_util 917 , Ratio:  0.30566666666666664\n",
            "initial_list_status 1 , Ratio:  0.0003333333333333333\n",
            "last_pymnt_d 95 , Ratio:  0.03166666666666667\n",
            "last_credit_pull_d 102 , Ratio:  0.034\n",
            "application_type 1 , Ratio:  0.0003333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform the actual optimization of the string columns"
      ],
      "metadata": {
        "id": "32VuvHoN1zi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns with less than 50% unique values to 'categorical'\n",
        "# chunck size is 3000\n",
        "\n",
        "# Reset\n",
        "df_loans_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
        "df_loans = next(df_loans_iter)\n",
        "df_loans_string = df_loans.select_dtypes(include=['object'])\n",
        "\n",
        "def to_categorical(df, num_rows):\n",
        "    # num_rows is the number of rows in the chunk\n",
        "    for col in df:\n",
        "        if len(df[col].value_counts()) / num_rows < 0.5:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "# Testing to ascertain memory reduction\n",
        "print('Before optimization: ', df_loans_string.memory_usage(deep=True).sum())\n",
        "to_categorical(df_loans_string, 3000)\n",
        "print('After optimization: ', df_loans_string.memory_usage(deep=True).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIgrWUeJ2CCZ",
        "outputId": "eb99587e-96b8-4300-e5fe-1bdf5f7ecccf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before optimization:  4058892\n",
            "After optimization:  625612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-21c671e01568>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('category')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22oYzgXnxIcV"
      },
      "source": [
        "## 4. Optimizing Numeric Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv5C20YrxPID"
      },
      "source": [
        "It looks like we were able to realize some powerful memory savings by converting to the category type and converting string columns to numeric ones.\n",
        "\n",
        "Now let's optimize the numeric columns using the `pandas.to_numeric()` function.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "While working with dataframe chunks:\n",
        "* Identify float columns that contain missing values, and that we can convert to a more space efficient subtype.\n",
        "* Identify float columns that don't contain any missing values, and that we can convert to the integer type because they represent whole numbers.\n",
        "* Based on your conclusions, perform the necessary type changes across all chunks.\n",
        "* Calculate the total memory footprint and compare it with the previous one.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numeric columns without missing values\n",
        "These can potentially be converted from floats to integers"
      ],
      "metadata": {
        "id": "yeCPgGEt2KwX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S9KR57LxQ9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2fc341-3be2-45cf-cb58-607fe6b39c58"
      },
      "source": [
        "# float columns without missing values\n",
        "df_loans_numeric = df_loans.select_dtypes(include=['float16', 'float32', 'float64'])\n",
        "for col in df_loans_numeric:\n",
        "    num_missing_vals = df_loans_numeric[col].isnull().sum()\n",
        "    print(col,  '=> Missing values: ', num_missing_vals) # 3000 is the chunksize\n",
        "\n",
        "# From inspecting the output below, non of the float columns have missing values\n",
        "# They are therefore all candidates for conversion to integers\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "member_id => Missing values:  0\n",
            "loan_amnt => Missing values:  0\n",
            "funded_amnt => Missing values:  0\n",
            "funded_amnt_inv => Missing values:  0\n",
            "installment => Missing values:  0\n",
            "annual_inc => Missing values:  0\n",
            "dti => Missing values:  0\n",
            "delinq_2yrs => Missing values:  0\n",
            "inq_last_6mths => Missing values:  0\n",
            "open_acc => Missing values:  0\n",
            "pub_rec => Missing values:  0\n",
            "revol_bal => Missing values:  0\n",
            "total_acc => Missing values:  0\n",
            "out_prncp => Missing values:  0\n",
            "out_prncp_inv => Missing values:  0\n",
            "total_pymnt => Missing values:  0\n",
            "total_pymnt_inv => Missing values:  0\n",
            "total_rec_prncp => Missing values:  0\n",
            "total_rec_int => Missing values:  0\n",
            "total_rec_late_fee => Missing values:  0\n",
            "recoveries => Missing values:  0\n",
            "collection_recovery_fee => Missing values:  0\n",
            "last_pymnt_amnt => Missing values:  0\n",
            "collections_12_mths_ex_med => Missing values:  0\n",
            "policy_code => Missing values:  0\n",
            "acc_now_delinq => Missing values:  0\n",
            "chargeoff_within_12_mths => Missing values:  0\n",
            "delinq_amnt => Missing values:  0\n",
            "pub_rec_bankruptcies => Missing values:  0\n",
            "tax_liens => Missing values:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform the actual optimization of numeric columns"
      ],
      "metadata": {
        "id": "He9Px_gE2hIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert float columns without missing values to integers\n",
        "\n",
        "# Reset\n",
        "df_loans_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
        "df_loans = next(df_loans_iter)\n",
        "df_loans_numeric = df_loans.select_dtypes(include=['float16', 'float32', 'float64'])\n",
        "\n",
        "def to_integers(df):\n",
        "    for col in df:\n",
        "        if is_numeric_dtype(df[col]):\n",
        "            if df[col].isnull().sum() == 0:\n",
        "                df[col] = df[col].astype('int')\n",
        "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "\n",
        "# Testing to ascertain memory reduction\n",
        "print('Before optimization: ', df_loans_numeric.memory_usage(deep=True).sum())\n",
        "to_integers(df_loans_numeric)\n",
        "print('After optimization: ', df_loans_numeric.memory_usage(deep=True).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmFHks822o1l",
        "outputId": "85b13bf6-1bd9-480c-804f-dd4164aece7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before optimization:  720128\n",
            "After optimization:  201128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-9fe6712e3d7f>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('int')\n",
            "<ipython-input-13-9fe6712e3d7f>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = pd.to_numeric(df[col], downcast='integer')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Assess the footprint improvements"
      ],
      "metadata": {
        "id": "gJL3jmkj2xar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory usage across all chunks"
      ],
      "metadata": {
        "id": "6O7h9g7J3bEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory usage across all the chunks\n",
        "\n",
        "# Reset the iterable\n",
        "df_loans_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
        "\n",
        "memory_used_without_optimization = 0\n",
        "memory_used_with_optimization = 0\n",
        "\n",
        "# Iterate over all the chunks\n",
        "for df_loans in df_loans_iter:\n",
        "    memory_used_without_optimization += df_loans.memory_usage(deep=True).sum()\n",
        "\n",
        "    df_loans_string = df_loans.select_dtypes(include=['object'])\n",
        "    df_loans_numeric = df_loans.select_dtypes(include=['float16', 'float32', 'float64'])\n",
        "\n",
        "    # Optimize strings and numerics\n",
        "    to_categorical(df_loans_string, 3000)\n",
        "    to_integers(df_loans_numeric)\n",
        "\n",
        "    memory_used_with_optimization += df_loans_string.memory_usage(deep=True).sum()\n",
        "    memory_used_with_optimization += df_loans_numeric.memory_usage(deep=True).sum()\n",
        "\n",
        "print('Total memory across chunks (before optimization): ', memory_used_without_optimization)\n",
        "print('Total memory across chunks (after optimization): ', memory_used_with_optimization)\n",
        "\n",
        "# From the output below, memory across chunks is 68.9MB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NgU4CdB3Btn",
        "outputId": "ee6c890b-e1ec-4c7e-ad6f-e1455231efd0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-21c671e01568>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('category')\n",
            "<ipython-input-13-9fe6712e3d7f>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('int')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total memory across chunks (before optimization):  68411731\n",
            "Total memory across chunks (after optimization):  13548992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMJVaj_kxj42"
      },
      "source": [
        "# 6. Automating the work above"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The task here is to automate the tasks in the cells above\n",
        "\n",
        "# Determine the optimal chunk size\n",
        "def optimal_chunk_size(file_name, mem_available):\n",
        "    # num_rows is the initial guess for the number of rows that will yield suitably-sized chunks\n",
        "    # The size of each chunk should ideally be less than 0.45 of mem_available; taking 0.45 to be on the safe side.\n",
        "    num_rows = 1000\n",
        "\n",
        "    df = pd.read_csv(file_name, nrows=num_rows)\n",
        "    chunk_memory = df.memory_usage(deep=True).sum()\n",
        "    # Estimate memory per row\n",
        "    mem_per_row = chunk_memory / num_rows\n",
        "    # Determine how many rows will achieve 0.45 x mem_available\n",
        "    optimal_num_rows = int((mem_available * 0.45) / mem_per_row)\n",
        "    \n",
        "    # Run (uncomment) the 3 lines below if testing\n",
        "    # df = pd.read_csv(file_name, nrows=optimal_num_rows)\n",
        "    # Print, during dev, for testing purposes only\n",
        "    # print(df.memory_usage(deep=True).sum())\n",
        "\n",
        "    return optimal_num_rows\n",
        "\n",
        "\n",
        "# The function below automates the tasks discussed in the cells above.\n",
        "# IT CAN BE RUN ON ALL THE CHUNKS BY ITERATING OVER THEM APPROPRIATELY\n",
        "\n",
        "def process_dataset(df, optimal_num_rows):\n",
        "    '''\n",
        "    Parameters:\n",
        "    - file_name: the name of the csv file from which to read data\n",
        "    - optimal_num_rows: the number of rows to give the desired chunk size\n",
        "    '''   \n",
        "    # 1. STRIP TRAILING '%' FROM STRING COLUMNS\n",
        "    # strip_string() was defined in one of the cells above\n",
        "    strip_strings(df, '%')\n",
        "\n",
        "    # 2. CONVERT OPTIMIZATION ON STRING COLUMNS\n",
        "    # to_categorical() was defined in one of the cells above\n",
        "    to_categorical(df, optimal_num_rows)\n",
        "\n",
        "    # 3. CONVERT FLOATS TO INTEGERS\n",
        "    # to_integer() was defined earlier\n",
        "    to_integers(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Test the entire shebang!\n",
        "chunk_size = optimal_chunk_size('loans_2007.csv', 10000000) # Assuming ~10MB available\n",
        "\n",
        "# Running without automating function\n",
        "df_iter = pd.read_csv('loans_2007.csv', chunksize=chunk_size)\n",
        "df = next(df_iter)\n",
        "print('Memory usage without optimization', df.memory_usage(deep=True).sum())\n",
        "\n",
        "# Running with automating function\n",
        "df_iter = pd.read_csv('loans_2007.csv', chunksize=chunk_size)\n",
        "df = next(df_iter)\n",
        "process_dataset(df, chunk_size) # This is the automation\n",
        "print('Memory usage without optimization', df.memory_usage(deep=True).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPAg7YwT31v4",
        "outputId": "4a1ebb5d-59f9-4ed4-f8a7-d59570d61e9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage without optimization 4497465\n",
            "Memory usage without optimization 935785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0RL3BzexlkW"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "From the output of the cell above, the memory usage before optimization was 68.9Mb whereas after optimization is is 13.9MB.\n",
        "\n",
        "It is possible that further optimizations are possible."
      ]
    }
  ]
}